INFO:Calentando motores...
INFO:[17/Jun/2016:16:32:09] ENGINE Bus STARTING
INFO:[17/Jun/2016:16:32:09] ENGINE Started monitor thread 'Autoreloader'.
INFO:[17/Jun/2016:16:32:09] ENGINE Started monitor thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:32:10] ENGINE Serving on http://0.0.0.0:5432
INFO:[17/Jun/2016:16:32:10] ENGINE Bus STARTED
INFO:{u'no_spam': u'/home/jduarte/Documentos/JD/no_spam', u'spam': u'/home/jduarte/Documentos/JD/spam'}
ERROR:Exception on /entrenar_spam/ [POST]
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1817, in wsgi_app
    response = self.full_dispatch_request()
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1477, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1381, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1475, in full_dispatch_request
    rv = self.dispatch_request()
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1461, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "/home/jduarte/Workspace/TesisSpark/app.py", line 63, in entrenar_spam
    resultado = motor_clasificador.entrenar_spam(directorio["spam"], directorio["no_spam"])
  File "/home/jduarte/Workspace/TesisSpark/engine.py", line 52, in entrenar_spam
    impurity='gini', maxDepth=30, maxBins=32)
  File "/home/jduarte/Herramientas/spark/python/lib/pyspark.zip/pyspark/mllib/tree.py", line 379, in trainClassifier
    maxDepth, maxBins, seed)
  File "/home/jduarte/Herramientas/spark/python/lib/pyspark.zip/pyspark/mllib/tree.py", line 296, in _train
    maxDepth, maxBins, seed)
  File "/home/jduarte/Herramientas/spark/python/lib/pyspark.zip/pyspark/mllib/common.py", line 130, in callMLlibFunc
    return callJavaFunc(sc, api, *args)
  File "/home/jduarte/Herramientas/spark/python/lib/pyspark.zip/pyspark/mllib/common.py", line 123, in callJavaFunc
    return _java2py(sc, func(*args))
  File "/home/jduarte/Herramientas/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py", line 813, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/jduarte/Herramientas/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 45, in deco
    return f(*a, **kw)
  File "/home/jduarte/Herramientas/spark/python/lib/py4j-0.9-src.zip/py4j/protocol.py", line 308, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling o78.trainRandomForestModel.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 53.0 failed 1 times, most recent failure: Lost task 0.0 in stage 53.0 (TID 582, localhost): java.lang.OutOfMemoryError: Java heap space
	at java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3476)
	at java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3282)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1792)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at scala.collection.immutable.HashMap$SerializationProxy.readObject(HashMap.scala:516)
	at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1900)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at scala.collection.immutable.HashMap$SerializationProxy.readObject(HashMap.scala:516)
	at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1900)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:926)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:741)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:740)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:740)
	at org.apache.spark.mllib.tree.DecisionTree$.findBestSplits(DecisionTree.scala:651)
	at org.apache.spark.mllib.tree.RandomForest.run(RandomForest.scala:233)
	at org.apache.spark.mllib.tree.RandomForest$.trainClassifier(RandomForest.scala:289)
	at org.apache.spark.mllib.api.python.PythonMLLibAPI.trainRandomForestModel(PythonMLLibAPI.scala:751)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)
	at py4j.Gateway.invoke(Gateway.java:259)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:209)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.OutOfMemoryError: Java heap space
	at java.io.ObjectInputStream$HandleTable.grow(ObjectInputStream.java:3476)
	at java.io.ObjectInputStream$HandleTable.assign(ObjectInputStream.java:3282)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1792)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at scala.collection.immutable.HashMap$SerializationProxy.readObject(HashMap.scala:516)
	at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1900)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at scala.collection.immutable.HashMap$SerializationProxy.readObject(HashMap.scala:516)
	at sun.reflect.GeneratedMethodAccessor44.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1900)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2000)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1924)

INFO:Calentando motores...
INFO:[17/Jun/2016:16:51:56] ENGINE Bus STARTING
INFO:[17/Jun/2016:16:51:56] ENGINE Started monitor thread 'Autoreloader'.
INFO:[17/Jun/2016:16:51:56] ENGINE Started monitor thread '_TimeoutMonitor'.
ERROR:[17/Jun/2016:16:52:02] ENGINE Error in 'start' listener <bound method Server.start of <cherrypy._cpserver.Server object at 0x7f464f662d10>>
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/cherrypy/process/wspbus.py", line 203, in publish
    output.append(listener(*args, **kwargs))
  File "/usr/local/lib/python2.7/dist-packages/cherrypy/_cpserver.py", line 168, in start
    ServerAdapter.start(self)
  File "/usr/local/lib/python2.7/dist-packages/cherrypy/process/servers.py", line 170, in start
    wait_for_free_port(*self.bind_addr)
  File "/usr/local/lib/python2.7/dist-packages/cherrypy/process/servers.py", line 438, in wait_for_free_port
    raise IOError("Port %r not free on %r" % (port, host))
IOError: Port 5432 not free on '0.0.0.0'

ERROR:[17/Jun/2016:16:52:02] ENGINE Shutting down due to error in start listener:
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/cherrypy/process/wspbus.py", line 241, in start
    self.publish('start')
  File "/usr/local/lib/python2.7/dist-packages/cherrypy/process/wspbus.py", line 221, in publish
    raise exc
ChannelFailures: IOError("Port 5432 not free on '0.0.0.0'",)

INFO:[17/Jun/2016:16:52:02] ENGINE Bus STOPPING
INFO:[17/Jun/2016:16:52:02] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('0.0.0.0', 5432)) already shut down
INFO:[17/Jun/2016:16:52:02] ENGINE Stopped thread 'Autoreloader'.
INFO:[17/Jun/2016:16:52:02] ENGINE Stopped thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:52:02] ENGINE Bus STOPPED
INFO:[17/Jun/2016:16:52:02] ENGINE Bus EXITING
INFO:[17/Jun/2016:16:52:02] ENGINE Bus EXITED
INFO:[17/Jun/2016:16:53:11] ENGINE Restarting because /home/jduarte/Workspace/TesisSpark/server.py changed.
INFO:[17/Jun/2016:16:53:11] ENGINE Stopped thread 'Autoreloader'.
INFO:[17/Jun/2016:16:53:11] ENGINE Bus STOPPING
INFO:[17/Jun/2016:16:53:11] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('0.0.0.0', 5432)) shut down
INFO:[17/Jun/2016:16:53:11] ENGINE Stopped thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:53:11] ENGINE Bus STOPPED
INFO:[17/Jun/2016:16:53:11] ENGINE Bus EXITING
INFO:[17/Jun/2016:16:53:11] ENGINE Bus EXITED
INFO:[17/Jun/2016:16:53:11] ENGINE Waiting for child threads to terminate...
INFO:[17/Jun/2016:16:53:11] ENGINE Re-spawning /home/jduarte/Workspace/TesisSpark/server.py
ERROR:An error occurred while trying to connect to the Java server
Traceback (most recent call last):
  File "/home/jduarte/Herramientas/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py", line 690, in start
    self.socket.connect((self.address, self.port))
  File "/usr/lib/python2.7/socket.py", line 224, in meth
    return getattr(self._sock,name)(*args)
error: [Errno 111] Connection refused
INFO:Calentando motores...
INFO:[17/Jun/2016:16:54:07] ENGINE Bus STARTING
INFO:[17/Jun/2016:16:54:07] ENGINE Started monitor thread 'Autoreloader'.
INFO:[17/Jun/2016:16:54:07] ENGINE Started monitor thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:54:07] ENGINE Serving on http://0.0.0.0:5433
INFO:[17/Jun/2016:16:54:07] ENGINE Bus STARTED
INFO:[17/Jun/2016:16:54:21] ENGINE Keyboard Interrupt: shutting down bus
INFO:[17/Jun/2016:16:54:21] ENGINE Bus STOPPING
INFO:[17/Jun/2016:16:54:21] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('0.0.0.0', 5433)) shut down
INFO:[17/Jun/2016:16:54:21] ENGINE Stopped thread 'Autoreloader'.
INFO:[17/Jun/2016:16:54:21] ENGINE Stopped thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:54:21] ENGINE Bus STOPPED
INFO:[17/Jun/2016:16:54:21] ENGINE Bus EXITING
INFO:[17/Jun/2016:16:54:21] ENGINE Bus EXITED
INFO:[17/Jun/2016:16:54:21] ENGINE Waiting for child threads to terminate...
INFO:Calentando motores...
INFO:[17/Jun/2016:16:54:47] ENGINE Bus STARTING
INFO:[17/Jun/2016:16:54:47] ENGINE Started monitor thread 'Autoreloader'.
INFO:[17/Jun/2016:16:54:47] ENGINE Started monitor thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:54:47] ENGINE Serving on http://0.0.0.0:5433
INFO:[17/Jun/2016:16:54:47] ENGINE Bus STARTED
INFO:[17/Jun/2016:16:55:12] ENGINE Keyboard Interrupt: shutting down bus
INFO:[17/Jun/2016:16:55:12] ENGINE Bus STOPPING
INFO:[17/Jun/2016:16:55:12] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('0.0.0.0', 5433)) shut down
INFO:[17/Jun/2016:16:55:12] ENGINE Stopped thread 'Autoreloader'.
INFO:[17/Jun/2016:16:55:12] ENGINE Stopped thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:55:12] ENGINE Bus STOPPED
INFO:[17/Jun/2016:16:55:12] ENGINE Bus EXITING
INFO:[17/Jun/2016:16:55:12] ENGINE Bus EXITED
INFO:[17/Jun/2016:16:55:12] ENGINE Waiting for child threads to terminate...
INFO:Calentando motores...
INFO:[17/Jun/2016:16:58:13] ENGINE Bus STARTING
INFO:[17/Jun/2016:16:58:13] ENGINE Started monitor thread 'Autoreloader'.
INFO:[17/Jun/2016:16:58:13] ENGINE Started monitor thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:16:58:13] ENGINE Serving on http://0.0.0.0:5433
INFO:[17/Jun/2016:16:58:13] ENGINE Bus STARTED
INFO:{u'no_spam': u'/home/jduarte/Documentos/JD/no_spam', u'spam': u'/home/jduarte/Documentos/JD/spam'}
INFO:{u'humano': u'/home/jduarte/Workspace/datos/datos_cat/humano', u'ciborg': u'/home/jduarte/Workspace/datos/datos_cat/ciborg', u'bot': u'/home/jduarte/Workspace/datos/datos_cat/bot'}
INFO:Cargando archivos...
INFO:Calculo de features en tweetsRDD_humanos...
INFO:Calculando features para tweets...
INFO:Iniciando calculo de tweets por dia...
INFO:Iniciando calculo de tweets por hora...
INFO:Iniciando exploracion de las fuentes de los tweets...
INFO:Iniciando calculo de diversidad lexicografica...
INFO:Iniciando calculo del promedio de la longuitud de los tweets...
INFO:Iniciando calculo del ratio de respuestas...
INFO:Iniciando calculo del promedio de los hashtags...
INFO:Iniciando calculo del promedio de menciones...
INFO:Iniciando calculo del promedio de palabras por tweet...
INFO:Iniciando calculo del promedio de diversidad de palabras...
INFO:Iniciando calculo del ratio de urls...
INFO:Iniciando calculo del avg de tweets SPAM...
ERROR:Exception on /entrenar_juez/ [POST]
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1817, in wsgi_app
    response = self.full_dispatch_request()
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1477, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1381, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1475, in full_dispatch_request
    rv = self.dispatch_request()
  File "/usr/local/lib/python2.7/dist-packages/flask/app.py", line 1461, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File "/home/jduarte/Workspace/TesisSpark/app.py", line 43, in entrenar_juez
    resultado = motor_clasificador.entrenar_juez(directorio)
  File "/home/jduarte/Workspace/TesisSpark/engine.py", line 91, in entrenar_juez
    tweets_features_humanos = tools.tweets_features(tweets_RDD_humanos, sc, juez_spam)
  File "/home/jduarte/Workspace/TesisSpark/tools.py", line 482, in tweets_features
    _avg_spam = avg_spam(tweets_RDD, juez)
  File "/home/jduarte/Workspace/TesisSpark/tools.py", line 354, in avg_spam
    text_tweets = tweets.mapValues(lambda tweet: Row(features=tf.transform(tweet[3].split(" "))))
AttributeError: 'RandomForestModel' object has no attribute 'mapValues'
INFO:[17/Jun/2016:17:33:44] ENGINE Restarting because /home/jduarte/Workspace/TesisSpark/tools.py changed.
INFO:[17/Jun/2016:17:33:44] ENGINE Stopped thread 'Autoreloader'.
INFO:[17/Jun/2016:17:33:44] ENGINE Bus STOPPING
INFO:[17/Jun/2016:17:33:44] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('0.0.0.0', 5433)) shut down
INFO:[17/Jun/2016:17:33:44] ENGINE Stopped thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:17:33:44] ENGINE Bus STOPPED
INFO:[17/Jun/2016:17:33:44] ENGINE Bus EXITING
INFO:[17/Jun/2016:17:33:44] ENGINE Bus EXITED
INFO:[17/Jun/2016:17:33:44] ENGINE Waiting for child threads to terminate...
INFO:[17/Jun/2016:17:33:44] ENGINE Re-spawning /home/jduarte/Workspace/TesisSpark/server.py
INFO:Calentando motores...
INFO:[17/Jun/2016:17:34:20] ENGINE Bus STARTING
INFO:[17/Jun/2016:17:34:20] ENGINE Started monitor thread 'Autoreloader'.
INFO:[17/Jun/2016:17:34:20] ENGINE Started monitor thread '_TimeoutMonitor'.
INFO:[17/Jun/2016:17:34:20] ENGINE Serving on http://0.0.0.0:5433
INFO:[17/Jun/2016:17:34:20] ENGINE Bus STARTED
INFO:{u'humano': u'/home/jduarte/Workspace/datos/datos_cat/humano', u'ciborg': u'/home/jduarte/Workspace/datos/datos_cat/ciborg', u'bot': u'/home/jduarte/Workspace/datos/datos_cat/bot'}
INFO:Cargando archivos...
INFO:Calculo de features en tweetsRDD_humanos...
INFO:Calculando features para tweets...
INFO:Iniciando calculo de tweets por dia...
INFO:Iniciando calculo de tweets por hora...
INFO:Iniciando exploracion de las fuentes de los tweets...
INFO:Iniciando calculo de diversidad lexicografica...
INFO:Iniciando calculo del promedio de la longuitud de los tweets...
INFO:Iniciando calculo del ratio de respuestas...
INFO:Iniciando calculo del promedio de los hashtags...
INFO:Iniciando calculo del promedio de menciones...
INFO:Iniciando calculo del promedio de palabras por tweet...
INFO:Iniciando calculo del promedio de diversidad de palabras...
INFO:Iniciando calculo del ratio de urls...
INFO:Iniciando calculo del avg de tweets SPAM...
INFO:Registrando tablas...
INFO:Join entre tweets...
INFO:Calculo de features en tweetsRDD_bots...
INFO:Calculando features para tweets...
INFO:Iniciando calculo de tweets por dia...
INFO:Iniciando calculo de tweets por hora...
INFO:Iniciando exploracion de las fuentes de los tweets...
INFO:Iniciando calculo de diversidad lexicografica...
INFO:Iniciando calculo del promedio de la longuitud de los tweets...
INFO:Iniciando calculo del ratio de respuestas...
INFO:Iniciando calculo del promedio de los hashtags...
INFO:Iniciando calculo del promedio de menciones...
INFO:Iniciando calculo del promedio de palabras por tweet...
INFO:Iniciando calculo del promedio de diversidad de palabras...
INFO:Iniciando calculo del ratio de urls...
INFO:Iniciando calculo del avg de tweets SPAM...
INFO:Registrando tablas...
INFO:Join entre tweets...
INFO:Calculo de features en tweetsRDD_ciborgs...
INFO:Calculando features para tweets...
INFO:Iniciando calculo de tweets por dia...
INFO:Iniciando calculo de tweets por hora...
INFO:Iniciando exploracion de las fuentes de los tweets...
INFO:Iniciando calculo de diversidad lexicografica...
INFO:Iniciando calculo del promedio de la longuitud de los tweets...
INFO:Iniciando calculo del ratio de respuestas...
INFO:Iniciando calculo del promedio de los hashtags...
INFO:Iniciando calculo del promedio de menciones...
INFO:Iniciando calculo del promedio de palabras por tweet...
INFO:Iniciando calculo del promedio de diversidad de palabras...
INFO:Iniciando calculo del ratio de urls...
INFO:Iniciando calculo del avg de tweets SPAM...
INFO:Registrando tablas...
INFO:Join entre tweets...
INFO:Calculo de features en usuariosRDD_humanos...
INFO:Calculando features para usuarios...
INFO:Calculo de features en usuariosRDD_bots...
INFO:Calculando features para usuarios...
INFO:Calculo de features en usuariosRDD_ciborgs...
INFO:Calculando features para usuarios...
INFO:Realizando Union...
INFO:Realizando Join...
INFO:Entrenando juez...
INFO:Guardando modelo...
INFO:Finalizando...
INFO:[24/Jun/2016:11:33:02] ENGINE Keyboard Interrupt: shutting down bus
INFO:[24/Jun/2016:11:33:02] ENGINE Bus STOPPING
INFO:[24/Jun/2016:11:33:02] ENGINE HTTP Server cherrypy._cpwsgi_server.CPWSGIServer(('0.0.0.0', 5433)) shut down
INFO:[24/Jun/2016:11:33:02] ENGINE Stopped thread 'Autoreloader'.
INFO:[24/Jun/2016:11:33:02] ENGINE Stopped thread '_TimeoutMonitor'.
INFO:[24/Jun/2016:11:33:02] ENGINE Bus STOPPED
INFO:[24/Jun/2016:11:33:02] ENGINE Bus EXITING
INFO:[24/Jun/2016:11:33:02] ENGINE Bus EXITED
INFO:[24/Jun/2016:11:33:02] ENGINE Waiting for child threads to terminate...
